{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Modeling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Address Business Requirement 2: Develop a model to determine whether a given leaf is infected with powdery mildew.\n",
        "- Implement machine learning techniques to train and evaluate a classification model with hyperparameter tuning.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "Dataset Directories:\n",
        "- inputs/mildew_dataset_dataset/cherry-leaves/train\n",
        "- inputs/mildew_dataset_dataset/cherry-leaves/test\n",
        "- inputs/mildew_dataset_dataset/cherry-leaves/validation\n",
        "- Image Shape Embeddings: Precomputed embeddings from the Data Visualization Notebook.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Image distribution plot for training, validation, and test sets.\n",
        "- Implementation of image augmentation techniques with real-time sample visualization.\n",
        "- Class indices mapping for label interpretation during inference.\n",
        "- Feature scaling and selection pipeline using GridSearchCV. \n",
        "- Optimized model with hyperparameter tuning using GridSearchCV.\n",
        "- Best hyperparameter combination selected through cross-validation.\n",
        "- Trained machine learning model using the best configuration.\n",
        "- Saved trained model for future inference.\n",
        "- Learning curve plot illustrating model performance over epochs.\n",
        "- Model evaluation metrics (Accuracy, Precision, Recall, F1-score) saved as a pickle file.\n",
        "- Confusion matrix and classification report to analyze prediction performance.\n",
        "- Prediction on a randomly selected image from the test set with probability scores.\n",
        "- Multiple image predictions comparing ground truth vs. model predictions.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "- This notebook focuses on developing and training a classification model using the structured dataset.\n",
        "- Performance evaluation ensures that the model meets the defined business requirement.\n",
        "- Proper validation and testing procedures ensure model robustness before deployment.\n",
        "- The trained model will serve as the backbone for the mildew detection application, aiding in real-time predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "os.chdir('/workspace/powdery-mildew-detector')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set input directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "labels = os.listdir(train_path)\n",
        "print(\n",
        "    f\"Project Labels: {labels}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "### Number of images in train, test and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create an empty dictionary to store data\n",
        "data = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Frequency': []\n",
        "}\n",
        "\n",
        "# List of dataset folders\n",
        "folders = ['train', 'validation', 'test']\n",
        "\n",
        "# Go through each folder and label to count the images\n",
        "for folder in folders:\n",
        "    for label in labels:\n",
        "        row = {\n",
        "            'Set': folder,\n",
        "            'Label': label,\n",
        "            'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))  \n",
        "        }\n",
        "        for key, value in row.items():\n",
        "            data[key].append(value)\n",
        "        print(\n",
        "            f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Set plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Create a bar chart to show image distribution\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Initialize image data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Augment training image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 20  # Number of images processed in each batch\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='binary',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "# Print dataset information\n",
        "print(\"Class indices:\", train_set.class_indices)  # Dictionary mapping labels to indices\n",
        "print(\"Number of classes:\", len(train_set.class_indices))  # Total number of classes\n",
        "print(\"Total number of images in dataset:\", train_set.samples)  # Total number of images (before augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Augment validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the validation images: Normalize pixel values to the range [0, 1]\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='binary',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "# Display class indices (label mapping)\n",
        "print(validation_set.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Augment test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the test images: Normalize pixel values to the range [0, 1]\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='binary',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "# Display class indices (label mapping)\n",
        "print(test_set.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(train_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(validation_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(test_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    \"\"\" \n",
        "    Create a CNN model with multiple Conv2D and MaxPooling2D layers.\n",
        "    The model uses different filter sizes and layer structures \n",
        "    to extract features from images.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=image_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Early Stopping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Pipeline with Feature Scaling & Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pipeline_clf():\n",
        "    return Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feature_selection\", SelectFromModel(RandomForestClassifier(random_state=42))),\n",
        "        (\"model\", RandomForestClassifier(random_state=42))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Hyperparameter Grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"model__n_estimators\": [50, 100, 150],\n",
        "    \"model__max_depth\": [10, 20, None],\n",
        "    \"model__min_samples_split\": [2, 5, 10]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GridSearchCV with Recall Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scorer = make_scorer(recall_score, pos_label=1)\n",
        "grid_search = GridSearchCV(estimator=pipeline_clf(), param_grid=param_grid, cv=3, scoring=scorer, verbose=2, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "joblib.dump(best_model, f'outputs/{version}/best_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print Best Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion and next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
